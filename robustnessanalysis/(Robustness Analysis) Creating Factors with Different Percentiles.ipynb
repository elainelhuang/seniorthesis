{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d544c81-a42e-4f39-a0dc-0a7485231b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138a1d50-369e-43a8-bca9-460a730ad3a6",
   "metadata": {},
   "source": [
    "# Creating the GMB Factors Using Different Percentiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cca2b90-bbc8-46a4-9e29-f1a4da37972f",
   "metadata": {},
   "source": [
    "* The Baseline cases use the 95th and 5th percentiles\n",
    "* \"Stricter Case\" uses 97.5th and 2.5th percentiles\n",
    "* \"Wider Case\" uses 90th and 10th percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2dd2daf-928d-4a4e-8e86-7ccd91ffb11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('relevantdata.csv')\n",
    "data['monthyear'] = data['year'].astype(str) + data['Month'].astype(str).str.zfill(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56a73744-4412-4d34-ae4e-ef02044c90d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where column 'sector' is equal to 'DidNotIdentify' (can't make assumptions if we don't know the sector)\n",
    "data = data[data['sector'] != 'DidNotIdentify']\n",
    "\n",
    "# Drop sectors that comprise of less than 1% of the total dataset\n",
    "data = data[data['sector'] != 'Management']\n",
    "data = data[data['sector'] != 'Agriculture']\n",
    "data = data[data['sector'] != 'ArtsEntRec']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fc78e0a-3e8f-4e0b-aee6-1c366c12137f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_method(method):\n",
    "    if method == 'Reported':\n",
    "        return 'Reported'\n",
    "    else:\n",
    "        return 'Estimated'\n",
    "\n",
    "data['Method'] = data['AnalyticCO2EstimationMethod'].apply(categorize_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d557f7b0-38e7-4fae-8041-fb56417fbaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = pd.date_range(start='2002-01-01', end='2023-12-01', freq='MS')\n",
    "monthyears = dates.strftime('%Y%m').tolist()\n",
    "monthyears = np.array(monthyears)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d496f319-eaa8-44ac-b28c-901df35a2026",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned = pd.get_dummies(data, columns=['Method'], dtype = int)\n",
    "cleaned.drop('AnalyticCO2EstimationMethod', axis=1, inplace=True)\n",
    "cleaned.rename(columns={'AnalyticEstimatesCO2EquivalentsEmissionTotal': 'CO2_Total'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13faaab1-fd2d-4a8a-930e-9508c8547d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate CO2 Emissions Data Transformations\n",
    "import numpy as np\n",
    "cleaned['ShiftedCO2'] = cleaned['CO2_Total'] + 0.00000001\n",
    "cleaned['LogCO2'] = np.log(cleaned['ShiftedCO2'])\n",
    "cleaned['CO2_Intensity'] = cleaned['CO2_Total']/cleaned['TotalAssets']\n",
    "\n",
    "# Only need one indicator\n",
    "cleaned.drop('Method_Reported', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02d17ab2-59ba-4c77-832b-1350c40a0531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_FF_factor(data, ESGmeasure, newcolumnname, lowerquant, upperquant):\n",
    "    portfolio_stocks_cusips = pd.DataFrame()\n",
    "    portfolio_stocks_sectors = pd.DataFrame()\n",
    "    portfolio_stocks = pd.DataFrame()\n",
    "    monthly_factors = np.zeros(shape=(len(monthyears), 2))\n",
    "    for i in range(len(monthyears)):\n",
    "        monthly_factors[i][0] = monthyears[i]\n",
    "        subset = (data[data['monthyear'] == monthyears[i]]).copy()\n",
    "        \n",
    "        # Calculate the Lower and Upper Quantiles (as specified)\n",
    "        q_lower = subset[ESGmeasure].quantile(lowerquant)\n",
    "        q_upper = subset[ESGmeasure].quantile(upperquant)\n",
    "        \n",
    "        # Filter the DataFrame\n",
    "        # filtered = subset[(subset[ESGmeasure] < q_lower) | (subset[ESGmeasure] > q_upper)]\n",
    "        # brown stocks have high CO2 emissions\n",
    "        brown = (subset[(subset[ESGmeasure] > q_upper)]).copy()\n",
    "        # green stocks have low CO2 emissions\n",
    "        green = (subset[(subset[ESGmeasure] < q_lower)]).copy()\n",
    "        \n",
    "        # subset['rank'] = subset[ESGmeasure].rank(method='first')\n",
    "        # n = len(subset)\n",
    "        # bottom_n = int(n*lowerquant)\n",
    "        # upper_n = int(n*upperquant)\n",
    "        # green = subset.nsmallest(bottom_n, ESGmeasure).copy()\n",
    "        # brown = subset.nlargest(upper_n, ESGmeasure).copy()\n",
    "        \n",
    "        filtered = pd.concat([green, brown], axis=0)\n",
    "        portfolio_stocks = pd.concat([portfolio_stocks, filtered], axis=0)\n",
    "        \n",
    "        new_stocks = pd.DataFrame({monthyears[i]: filtered['cusip'].to_list()})\n",
    "        portfolio_stocks_cusips = pd.concat([portfolio_stocks_cusips, new_stocks], axis=1)\n",
    "        \n",
    "        new_sectors = pd.DataFrame({monthyears[i]: filtered['sector'].to_list()})\n",
    "        portfolio_stocks_sectors = pd.concat([portfolio_stocks_sectors, new_sectors], axis=1)\n",
    "\n",
    "        # Calculate the (equal) weight of each of the stocks in the selected portfolio\n",
    "        equalweight = 1/filtered.shape[0]\n",
    "\n",
    "        # Calculate long and short returns\n",
    "        green['WeightedReturn'] = green['ExcessReturn'] * equalweight\n",
    "        brown['WeightedReturn'] = brown['ExcessReturn'] * equalweight\n",
    "        \n",
    "        green_sum = green['WeightedReturn'].sum()\n",
    "        brown_sum = brown['WeightedReturn'].sum()\n",
    "\n",
    "        # Long green stocks and short brown stocks\n",
    "        monthly_factor = green_sum - brown_sum\n",
    "        monthly_factors[i][1] = monthly_factor * 100\n",
    "        \n",
    "    df = pd.DataFrame(monthly_factors)\n",
    "    df.columns = ['monthyear', newcolumnname]\n",
    "    df['monthyear'] = df['monthyear'].astype(str) \n",
    "    df['monthyear'] = df['monthyear'].str.replace(r'\\.0$', '', regex=True)\n",
    "    return df, portfolio_stocks_cusips, portfolio_stocks_sectors, portfolio_stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7847ce37-5ff8-4020-9774-00b65e66c871",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_strict = cleaned.copy()\n",
    "cleaned_wide = cleaned.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dca4fa1-81e4-45a3-ac34-99a42485ec72",
   "metadata": {},
   "source": [
    "## \"Stricter Case\" (97.5th and 2.5th percentiles) - Factor Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eecc8017-4d34-4e6b-95ae-c8ba327653d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "factordata_strict = cleaned_strict[['cusip', 'year', 'Month', 'monthyear', 'Mkt-RF', 'SMB', 'HML', 'RF', 'RMW', 'CMA', 'RET', 'ExcessReturn', 'sector', 'CO2_Total', 'TotalAssets', 'LogCO2', 'CO2_Intensity', 'Method_Estimated']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b6e5c6d-5933-4592-909e-1c46683f9ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_quant_strict = 0.025\n",
    "u_quant_strict = 0.975\n",
    "\n",
    "# LogCO2\n",
    "LogCO2_factors_strict, LogCO2_cusips_strict, LogCO2_sectors_strict, LogCO2_portfolio_strict = create_FF_factor(cleaned_strict, 'LogCO2', 'GMB_U', l_quant_strict, u_quant_strict)\n",
    "factordata_strict = pd.merge(factordata_strict, LogCO2_factors_strict, on=['monthyear'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "548b3540-ce46-4c70-b9c7-0f1f7ba29fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CO2 Intensity\n",
    "CO2Intensity_factors_strict, CO2Intensity_cusips_strict, CO2Intensity_sectors_strict, CO2Intensity_portfolio_strict = create_FF_factor(cleaned_strict, 'CO2_Intensity', 'GMB_S', l_quant_strict, u_quant_strict)\n",
    "factordata_strict = pd.merge(factordata_strict, CO2Intensity_factors_strict, on=['monthyear'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e824bff6-edf4-4712-9196-a4471a0e247f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export factors to .csv file\n",
    "factordata_strict.to_csv('factordata_strict.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3925af7-dcc2-4279-a3ea-4ca764205d3b",
   "metadata": {},
   "source": [
    "## \"Wider Case\" (90th and 10th percentiles) - Factor Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "96707f44-bde6-4798-8b02-a43614b147ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "factordata_wide = cleaned_wide[['cusip', 'year', 'Month', 'monthyear', 'Mkt-RF', 'SMB', 'HML', 'RF', 'RMW', 'CMA', 'RET', 'ExcessReturn', 'sector', 'CO2_Total', 'TotalAssets', 'LogCO2', 'CO2_Intensity', 'Method_Estimated']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff014d27-5f47-4704-98bd-89841ab53b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_quant_wide = 0.10\n",
    "u_quant_wide = 0.90\n",
    "\n",
    "# LogCO2\n",
    "LogCO2_factors_wide, LogCO2_cusips_wide, LogCO2_sectors_wide, LogCO2_portfolio_wide = create_FF_factor(cleaned_wide, 'LogCO2', 'GMB_U', l_quant_wide, u_quant_wide)\n",
    "factordata_wide = pd.merge(factordata_wide, LogCO2_factors_wide, on=['monthyear'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0eab31c0-d67e-431d-a2cc-cede7b2e1470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CO2 Intensity\n",
    "CO2Intensity_factors_wide, CO2Intensity_cusips_wide, CO2Intensity_sectors_wide, CO2Intensity_portfolio_wide = create_FF_factor(cleaned_wide, 'CO2_Intensity', 'GMB_S', l_quant_wide, u_quant_wide)\n",
    "factordata_wide = pd.merge(factordata_wide, CO2Intensity_factors_wide, on=['monthyear'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "133dec55-8e07-4254-9920-e9442b813917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export factors to .csv file\n",
    "factordata_wide.to_csv('factordata_wide.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
